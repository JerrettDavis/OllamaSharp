<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>OllamaSharp &#129433; | OllamaSharp </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="OllamaSharp &#129433; | OllamaSharp ">
      
      
      <link rel="icon" href="favicon.ico">
      <link rel="stylesheet" href="public/docfx.min.css">
      <link rel="stylesheet" href="public/main.css">
      <meta name="docfx:navrel" content="toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="">
      
      
      <meta name="docfx:docurl" content="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/README.md/#L1">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="index.html">
            <img id="logo" class="svg" src="logo.svg" alt="OllamaSharp">
            OllamaSharp
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled="" placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">

      <div class="content">
        <div class="actionbar">

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="">

<p align="center">
 <img alt="ollama" height="200px" src="https://github.com/awaescher/OllamaSharp/blob/main/Ollama.png">
</p>
<h1 id="ollamasharp-">OllamaSharp 🦙</h1>
<p>OllamaSharp provides .NET bindings for the <a href="https://github.com/jmorganca/ollama/blob/main/docs/api.md">Ollama API</a>, simplifying interactions with Ollama both locally and remotely.</p>
<p>✅ Supporting <a href="https://devblogs.microsoft.com/dotnet/introducing-microsoft-extensions-ai-preview/">Microsoft.Extensions.AI</a> and <a href="https://github.com/microsoft/semantic-kernel/pull/7362">Microsoft Semantic Kernel</a></p>
<h2 id="features">Features</h2>
<ul>
<li>Ease of use: Interact with Ollama in just a few lines of code.</li>
<li>API endpoint coverage: Support for all the Ollama API endpoints, including chats, embeddings, listing models, pulling and creating new models, and more.</li>
<li>Real-time streaming: Stream responses directly to your application.</li>
<li>Progress reporting: Get real-time progress feedback on tasks like model pulling.</li>
<li>Support for <a href="https://ollama.com/blog/vision-models">vision models</a> and <a href="https://ollama.com/blog/tool-support">tools (function calling)</a>.</li>
</ul>
<h2 id="usage">Usage</h2>
<p>OllamaSharp wraps each Ollama API endpoint in awaitable methods that fully support response streaming.</p>
<p>The following list shows a few simple code examples.</p>
<p>ℹ <strong>Try our full featured <a href="./demo">demo application</a> that's included in this repository</strong></p>
<h3 id="initializing">Initializing</h3>
<pre><code class="lang-csharp">// set up the client
var uri = new Uri(&quot;http://localhost:11434&quot;);
var ollama = new OllamaApiClient(uri);

// select a model which should be used for further operations
ollama.SelectedModel = &quot;llama3.1:8b&quot;;
</code></pre>
<h3 id="listing-all-models-that-are-available-locally">Listing all models that are available locally</h3>
<pre><code class="lang-csharp">var models = await ollama.ListLocalModelsAsync();
</code></pre>
<h3 id="pulling-a-model-and-reporting-progress">Pulling a model and reporting progress</h3>
<pre><code class="lang-csharp">await foreach (var status in ollama.PullModelAsync(&quot;llama3.1:405b&quot;))
    Console.WriteLine($&quot;{status.Percent}% {status.Status}&quot;);
</code></pre>
<h3 id="generating-a-completion-directly-into-the-console">Generating a completion directly into the console</h3>
<pre><code class="lang-csharp">await foreach (var stream in ollama.GenerateAsync(&quot;How are you today?&quot;))
    Console.Write(stream.Response);
</code></pre>
<h3 id="building-interactive-chats">Building interactive chats</h3>
<pre><code class="lang-csharp">var chat = new Chat(ollama);
while (true)
{
    var message = Console.ReadLine();
    await foreach (var answerToken in chat.SendAsync(message))
        Console.Write(answerToken);
}
// messages including their roles and tool calls will automatically be tracked within the chat object
// and are accessible via the Messages property
</code></pre>
<h2 id="usage-with-microsoftextensionsai">Usage with Microsoft.Extensions.AI</h2>
<p>Microsoft built an abstraction library to streamline the usage of different AI providers. This is a really interesting concept if you plan to build apps that might use different providers, like ChatGPT, Claude and local models with Ollama.</p>
<p>I encourage you to read their accouncement <a href="https://devblogs.microsoft.com/dotnet/introducing-microsoft-extensions-ai-preview/">Introducing Microsoft.Extensions.AI Preview – Unified AI Building Blocks for .NET</a>.</p>
<p>OllamaSharp is the first full implementation of their <code>IChatClient</code> and <code>IEmbeddingGenerator</code> that makes it possible to use Ollama just like every other chat provider.</p>
<p>To do this, simply use the <code>OllamaApiClient</code> as <code>IChatClient</code> instead of <code>IOllamaApiClient</code>.</p>
<pre><code class="lang-csharp">// install package Microsoft.Extensions.AI.Abstractions

private static IChatClient CreateChatClient(Arguments arguments)
{
  if (arguments.Provider.Equals(&quot;ollama&quot;, StringComparison.OrdinalIgnoreCase))
    return new OllamaApiClient(arguments.Uri, arguments.Model);
  else
    return new OpenAIChatClient(new OpenAI.OpenAIClient(arguments.ApiKey), arguments.Model); // ChatGPT or compatible
}
</code></pre>
<div class="NOTE">
<h5>Note</h5>
<p><code>IOllamaApiClient</code> provides many Ollama specific methods that <code>IChatClient</code> and <code>IEmbeddingGenerator</code> miss. Because these are abstractions, <code>IChatClient</code> and <code>IEmbeddingGenerator</code> will never implement the full Ollama API specification. However, <code>OllamaApiClient</code> implements three interfaces: the native <code>IOllamaApiClient</code> and Microsoft <code>IChatClient</code> and <code>IEmbeddingGenerator&lt;string, Embedding&lt;float&gt;&gt;</code> which allows you to cast it to any of these two interfaces as you need them at any time.</p>
</div>
<h2 id="credits">Credits</h2>
<p>The icon and name were reused from the amazing <a href="https://github.com/jmorganca/ollama">Ollama project</a>.</p>
<p><strong>I would like to thank all the contributors who take the time to improve OllamaSharp. First and foremost <a href="https://github.com/mili-tan">mili-tan</a>, who always keeps OllamaSharp in sync with the Ollama API. ❤</strong></p>

</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/README.md/#L1" class="edit-link">Edit this page</a>
        </div>

        <div class="next-article d-print-none border-top" id="nextArticle"></div>

      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          <span>Made with <a href="https://dotnet.github.io/docfx">docfx</a></span>
        </div>
      </div>
    </footer>
  </body>
</html>
