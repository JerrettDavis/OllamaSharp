<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class Chat | OllamaSharp </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class Chat | OllamaSharp ">
      
      <meta name="description" content="A chat helper that handles the chat logic internally and automatically extends the message history.  A simple interactive chat can be implemented in just a handful of lines: var ollama = new OllamaApiClient(&quot;http://localhost:11434&quot;, &quot;llama3.2-vision:latest&quot;); var chat = new Chat(ollama); // ... while (true) { 	Console.Write(&quot;You: &quot;); 	var message = Console.ReadLine()!; 	Console.Write(&quot;Ollama: &quot;); 	await foreach (var answerToken in chat.SendAsync(message)) 		Console.Write(answerToken); 	// ... 	Console.WriteLine(); } // ... // Output: // You: Write a haiku about AI models // Ollama: Code whispers secrets //   Intelligent designs unfold //   Minds beyond our own">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/JerrettDavis/OllamaSharp/new/feature/add-documentation/apiSpec/new?filename=OllamaSharp_Chat.md&amp;value=---%0Auid%3A%20OllamaSharp.Chat%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="OllamaSharp">
            OllamaSharp
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled="" placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="OllamaSharp.Chat">



  <h1 id="OllamaSharp_Chat" data-uid="OllamaSharp.Chat" class="text-break">
Class Chat  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L41"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="OllamaSharp.html">OllamaSharp</a></dd></dl>
  <dl><dt>Assembly</dt><dd>OllamaSharp.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>A chat helper that handles the chat logic internally and
automatically extends the message history.</p>
<example>
A simple interactive chat can be implemented in just a handful of lines:
<pre><code class="lang-csharp">var ollama = new OllamaApiClient("http://localhost:11434", "llama3.2-vision:latest");
var chat = new Chat(ollama);
// ...
while (true)
{
	Console.Write("You: ");
	var message = Console.ReadLine()!;
	Console.Write("Ollama: ");
	await foreach (var answerToken in chat.SendAsync(message))
		Console.Write(answerToken);
	// ...
	Console.WriteLine();
}
// ...
// Output:
// You: Write a haiku about AI models
// Ollama: Code whispers secrets
//   Intelligent designs unfold
//   Minds beyond our own</code></pre></example>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class Chat</code></pre>
  </div>




  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><span class="xref">Chat</span></div>
    </dd>
  </dl>



  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>






  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="OllamaSharp_Chat__ctor_" data-uid="OllamaSharp.Chat.#ctor*"></a>

  <h3 id="OllamaSharp_Chat__ctor_OllamaSharp_IOllamaApiClient_System_String_" data-uid="OllamaSharp.Chat.#ctor(OllamaSharp.IOllamaApiClient,System.String)">
  Chat(IOllamaApiClient, string)
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L79"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Creates a new chat instance</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Chat(IOllamaApiClient client, string systemPrompt = &quot;&quot;)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>client</code> <a class="xref" href="OllamaSharp.IOllamaApiClient.html">IOllamaApiClient</a></dt>
    <dd><p>The Ollama client to use for the chat</p>
</dd>
    <dt><code>systemPrompt</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>An optional system prompt to define the behavior of the chat assistant</p>
</dd>
  </dl>







  <h4 class="section" id="OllamaSharp_Chat__ctor_OllamaSharp_IOllamaApiClient_System_String__examples">Examples</h4>
  <p>Setting up a chat with a system prompt:</p>
<pre><code class="lang-csharp">var client = new OllamaApiClient("http://localhost:11434", "llama3.2-vision:latest");
var prompt = "You are a helpful assistant that will answer any question you are asked.";
var chat = new Chat(client, prompt);</code></pre>



  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>If the client is null, an <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a> is thrown.</p>
</dd>
  </dl>



  <h2 class="section" id="properties">Properties
</h2>


  <a id="OllamaSharp_Chat_Client_" data-uid="OllamaSharp.Chat.Client*"></a>

  <h3 id="OllamaSharp_Chat_Client" data-uid="OllamaSharp.Chat.Client">
  Client
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L51"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the Ollama API client</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IOllamaApiClient Client { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="OllamaSharp.IOllamaApiClient.html">IOllamaApiClient</a></dt>
    <dd></dd>
  </dl>








  <a id="OllamaSharp_Chat_Messages_" data-uid="OllamaSharp.Chat.Messages*"></a>

  <h3 id="OllamaSharp_Chat_Messages" data-uid="OllamaSharp.Chat.Messages">
  Messages
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L46"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the messages of the chat history</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public List&lt;Message&gt; Messages { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.list-1">List</a>&lt;<a class="xref" href="OllamaSharp.Models.Chat.Message.html">Message</a>&gt;</dt>
    <dd></dd>
  </dl>








  <a id="OllamaSharp_Chat_Model_" data-uid="OllamaSharp.Chat.Model*"></a>

  <h3 id="OllamaSharp_Chat_Model" data-uid="OllamaSharp.Chat.Model">
  Model
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L56"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the AI model to chat with</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public string Model { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd></dd>
  </dl>








  <a id="OllamaSharp_Chat_Options_" data-uid="OllamaSharp.Chat.Options*"></a>

  <h3 id="OllamaSharp_Chat_Options" data-uid="OllamaSharp.Chat.Options">
  Options
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L61"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the RequestOptions to chat with</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public RequestOptions? Options { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="OllamaSharp.Models.RequestOptions.html">RequestOptions</a></dt>
    <dd></dd>
  </dl>








  <h2 class="section" id="methods">Methods
</h2>


  <a id="OllamaSharp_Chat_SendAsAsync_" data-uid="OllamaSharp.Chat.SendAsAsync*"></a>

  <h3 id="OllamaSharp_Chat_SendAsAsync_OllamaSharp_Models_Chat_ChatRole_System_String_System_Collections_Generic_IEnumerable_System_Collections_Generic_IEnumerable_System_Byte___System_Threading_CancellationToken_" data-uid="OllamaSharp.Chat.SendAsAsync(OllamaSharp.Models.Chat.ChatRole,System.String,System.Collections.Generic.IEnumerable{System.Collections.Generic.IEnumerable{System.Byte}},System.Threading.CancellationToken)">
  SendAsAsync(ChatRole, string, IEnumerable&lt;IEnumerable&lt;byte&gt;&gt;?, CancellationToken)
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L186"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sends a message in a given role to the currently selected model and streams its response</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IAsyncEnumerable&lt;string&gt; SendAsAsync(ChatRole role, string message, IEnumerable&lt;IEnumerable&lt;byte&gt;&gt;? imagesAsBytes, CancellationToken cancellationToken = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>role</code> <a class="xref" href="OllamaSharp.Models.Chat.ChatRole.html">ChatRole</a></dt>
    <dd><p>The role in which the message should be sent</p>
</dd>
    <dt><code>message</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The message to send</p>
</dd>
    <dt><code>imagesAsBytes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.byte">byte</a>&gt;&gt;</dt>
    <dd><p>Images in byte representation to send to the model</p>
</dd>
    <dt><code>cancellationToken</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.cancellationtoken">CancellationToken</a></dt>
    <dd><p>The token to cancel the operation with</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd></dd>
  </dl>











  <a id="OllamaSharp_Chat_SendAsAsync_" data-uid="OllamaSharp.Chat.SendAsAsync*"></a>

  <h3 id="OllamaSharp_Chat_SendAsAsync_OllamaSharp_Models_Chat_ChatRole_System_String_System_Collections_Generic_IEnumerable_System_String__System_Threading_CancellationToken_" data-uid="OllamaSharp.Chat.SendAsAsync(OllamaSharp.Models.Chat.ChatRole,System.String,System.Collections.Generic.IEnumerable{System.String},System.Threading.CancellationToken)">
  SendAsAsync(ChatRole, string, IEnumerable&lt;string&gt;?, CancellationToken)
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L196"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sends a message in a given role to the currently selected model and streams its response</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IAsyncEnumerable&lt;string&gt; SendAsAsync(ChatRole role, string message, IEnumerable&lt;string&gt;? imagesAsBase64, CancellationToken cancellationToken = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>role</code> <a class="xref" href="OllamaSharp.Models.Chat.ChatRole.html">ChatRole</a></dt>
    <dd><p>The role in which the message should be sent</p>
</dd>
    <dt><code>message</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The message to send</p>
</dd>
    <dt><code>imagesAsBase64</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>Base64 encoded images to send to the model</p>
</dd>
    <dt><code>cancellationToken</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.cancellationtoken">CancellationToken</a></dt>
    <dd><p>The token to cancel the operation with</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd></dd>
  </dl>











  <a id="OllamaSharp_Chat_SendAsAsync_" data-uid="OllamaSharp.Chat.SendAsAsync*"></a>

  <h3 id="OllamaSharp_Chat_SendAsAsync_OllamaSharp_Models_Chat_ChatRole_System_String_System_Collections_Generic_IReadOnlyCollection_OllamaSharp_Models_Chat_Tool__System_Collections_Generic_IEnumerable_System_String__System_Threading_CancellationToken_" data-uid="OllamaSharp.Chat.SendAsAsync(OllamaSharp.Models.Chat.ChatRole,System.String,System.Collections.Generic.IReadOnlyCollection{OllamaSharp.Models.Chat.Tool},System.Collections.Generic.IEnumerable{System.String},System.Threading.CancellationToken)">
  SendAsAsync(ChatRole, string, IReadOnlyCollection&lt;Tool&gt;?, IEnumerable&lt;string&gt;?, CancellationToken)
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L207"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sends a message in a given role to the currently selected model and streams its response</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IAsyncEnumerable&lt;string&gt; SendAsAsync(ChatRole role, string message, IReadOnlyCollection&lt;Tool&gt;? tools, IEnumerable&lt;string&gt;? imagesAsBase64 = null, CancellationToken cancellationToken = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>role</code> <a class="xref" href="OllamaSharp.Models.Chat.ChatRole.html">ChatRole</a></dt>
    <dd><p>The role in which the message should be sent</p>
</dd>
    <dt><code>message</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The message to send</p>
</dd>
    <dt><code>tools</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ireadonlycollection-1">IReadOnlyCollection</a>&lt;<a class="xref" href="OllamaSharp.Models.Chat.Tool.html">Tool</a>&gt;</dt>
    <dd><p>Tools that the model can make use of, see <a href="https://ollama.com/blog/tool-support">https://ollama.com/blog/tool-support</a>. By using tools, response streaming is automatically turned off</p>
</dd>
    <dt><code>imagesAsBase64</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>Base64 encoded images to send to the model</p>
</dd>
    <dt><code>cancellationToken</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.cancellationtoken">CancellationToken</a></dt>
    <dd><p>The token to cancel the operation with</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd></dd>
  </dl>











  <a id="OllamaSharp_Chat_SendAsAsync_" data-uid="OllamaSharp.Chat.SendAsAsync*"></a>

  <h3 id="OllamaSharp_Chat_SendAsAsync_OllamaSharp_Models_Chat_ChatRole_System_String_System_Threading_CancellationToken_" data-uid="OllamaSharp.Chat.SendAsAsync(OllamaSharp.Models.Chat.ChatRole,System.String,System.Threading.CancellationToken)">
  SendAsAsync(ChatRole, string, CancellationToken)
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L176"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sends a message in a given role to the currently selected model and streams its response</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IAsyncEnumerable&lt;string&gt; SendAsAsync(ChatRole role, string message, CancellationToken cancellationToken = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>role</code> <a class="xref" href="OllamaSharp.Models.Chat.ChatRole.html">ChatRole</a></dt>
    <dd><p>The role in which the message should be sent</p>
</dd>
    <dt><code>message</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The message to send</p>
</dd>
    <dt><code>cancellationToken</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.cancellationtoken">CancellationToken</a></dt>
    <dd><p>The token to cancel the operation with</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd></dd>
  </dl>











  <a id="OllamaSharp_Chat_SendAsync_" data-uid="OllamaSharp.Chat.SendAsync*"></a>

  <h3 id="OllamaSharp_Chat_SendAsync_System_String_System_Collections_Generic_IEnumerable_System_Collections_Generic_IEnumerable_System_Byte___System_Threading_CancellationToken_" data-uid="OllamaSharp.Chat.SendAsync(System.String,System.Collections.Generic.IEnumerable{System.Collections.Generic.IEnumerable{System.Byte}},System.Threading.CancellationToken)">
  SendAsync(string, IEnumerable&lt;IEnumerable&lt;byte&gt;&gt;?, CancellationToken)
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L129"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sends a message to the currently selected model and streams its response</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IAsyncEnumerable&lt;string&gt; SendAsync(string message, IEnumerable&lt;IEnumerable&lt;byte&gt;&gt;? imagesAsBytes, CancellationToken cancellationToken = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>message</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The message to send</p>
</dd>
    <dt><code>imagesAsBytes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.byte">byte</a>&gt;&gt;</dt>
    <dd><p>Images in byte representation to send to the model</p>
</dd>
    <dt><code>cancellationToken</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.cancellationtoken">CancellationToken</a></dt>
    <dd><p>The token to cancel the operation with</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>An <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable&lt;T&gt;</a> that streams the response.</p>
</dd>
  </dl>






  <h4 class="section" id="OllamaSharp_Chat_SendAsync_System_String_System_Collections_Generic_IEnumerable_System_Collections_Generic_IEnumerable_System_Byte___System_Threading_CancellationToken__examples">Examples</h4>
  <p>Getting a response from the model with an image:</p>
<pre><code class="lang-csharp">var client = new HttpClient();
var cat = await client.GetByteArrayAsync("https://cataas.com/cat");
var ollama = new OllamaApiClient("http://localhost:11434", "llama3.2-vision:latest");
var chat = new Chat(ollama);
var response = chat.SendAsync("What do you see?", [cat]);
await foreach (var answerToken in response) Console.Write(answerToken);

// Output: The image shows a white kitten with black markings on its
//         head and tail, sitting next to an orange tabby cat. The kitten
//         is looking at the camera while the tabby cat appears to be
//         sleeping or resting with its eyes closed. The two cats are
//         lying in a blanket that has been rumpled up.</code></pre>






  <a id="OllamaSharp_Chat_SendAsync_" data-uid="OllamaSharp.Chat.SendAsync*"></a>

  <h3 id="OllamaSharp_Chat_SendAsync_System_String_System_Collections_Generic_IEnumerable_System_String__System_Threading_CancellationToken_" data-uid="OllamaSharp.Chat.SendAsync(System.String,System.Collections.Generic.IEnumerable{System.String},System.Threading.CancellationToken)">
  SendAsync(string, IEnumerable&lt;string&gt;?, CancellationToken)
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L157"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sends a message to the currently selected model and streams its response</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IAsyncEnumerable&lt;string&gt; SendAsync(string message, IEnumerable&lt;string&gt;? imagesAsBase64, CancellationToken cancellationToken = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>message</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The message to send</p>
</dd>
    <dt><code>imagesAsBase64</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>Base64 encoded images to send to the model</p>
</dd>
    <dt><code>cancellationToken</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.cancellationtoken">CancellationToken</a></dt>
    <dd><p>The token to cancel the operation with</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>An <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable&lt;T&gt;</a> that streams the response.</p>
</dd>
  </dl>






  <h4 class="section" id="OllamaSharp_Chat_SendAsync_System_String_System_Collections_Generic_IEnumerable_System_String__System_Threading_CancellationToken__examples">Examples</h4>
  <p>Getting a response from the model with an image:</p>
<pre><code class="lang-csharp">var client = new HttpClient();
var cat = await client.GetByteArrayAsync("https://cataas.com/cat");
var base64Cat = Convert.ToBase64String(cat);
var ollama = new OllamaApiClient("http://localhost:11434", "llama3.2-vision:latest");
var chat = new Chat(ollama);
var response = chat.SendAsync("What do you see?", [base64Cat]);
await foreach (var answerToken in response) Console.Write(answerToken);

// Output:
// The image shows a cat lying on the floor next to an iPad. The cat is looking
// at the screen, which displays a game with fish and other sea creatures. The
// cat's paw is touching the screen, as if it is playing the game. The background
// of the image is a wooden floor.</code></pre>






  <a id="OllamaSharp_Chat_SendAsync_" data-uid="OllamaSharp.Chat.SendAsync*"></a>

  <h3 id="OllamaSharp_Chat_SendAsync_System_String_System_Collections_Generic_IReadOnlyCollection_OllamaSharp_Models_Chat_Tool__System_Collections_Generic_IEnumerable_System_String__System_Threading_CancellationToken_" data-uid="OllamaSharp.Chat.SendAsync(System.String,System.Collections.Generic.IReadOnlyCollection{OllamaSharp.Models.Chat.Tool},System.Collections.Generic.IEnumerable{System.String},System.Threading.CancellationToken)">
  SendAsync(string, IReadOnlyCollection&lt;Tool&gt;?, IEnumerable&lt;string&gt;?, CancellationToken)
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L167"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sends a message to the currently selected model and streams its response</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IAsyncEnumerable&lt;string&gt; SendAsync(string message, IReadOnlyCollection&lt;Tool&gt;? tools, IEnumerable&lt;string&gt;? imagesAsBase64 = null, CancellationToken cancellationToken = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>message</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The message to send</p>
</dd>
    <dt><code>tools</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ireadonlycollection-1">IReadOnlyCollection</a>&lt;<a class="xref" href="OllamaSharp.Models.Chat.Tool.html">Tool</a>&gt;</dt>
    <dd><p>Tools that the model can make use of, see <a href="https://ollama.com/blog/tool-support">https://ollama.com/blog/tool-support</a>. By using tools, response streaming is automatically turned off</p>
</dd>
    <dt><code>imagesAsBase64</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>Base64 encoded images to send to the model</p>
</dd>
    <dt><code>cancellationToken</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.cancellationtoken">CancellationToken</a></dt>
    <dd><p>The token to cancel the operation with</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd></dd>
  </dl>











  <a id="OllamaSharp_Chat_SendAsync_" data-uid="OllamaSharp.Chat.SendAsync*"></a>

  <h3 id="OllamaSharp_Chat_SendAsync_System_String_System_Threading_CancellationToken_" data-uid="OllamaSharp.Chat.SendAsync(System.String,System.Threading.CancellationToken)">
  SendAsync(string, CancellationToken)
  <a class="header-action link-secondary" title="View source" href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L102"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sends a message to the currently selected model and streams its response</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IAsyncEnumerable&lt;string&gt; SendAsync(string message, CancellationToken cancellationToken = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>message</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The message to send</p>
</dd>
    <dt><code>cancellationToken</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.cancellationtoken">CancellationToken</a></dt>
    <dd><p>The token to cancel the operation with</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>An <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.iasyncenumerable-1">IAsyncEnumerable&lt;T&gt;</a> that streams the response.</p>
</dd>
  </dl>






  <h4 class="section" id="OllamaSharp_Chat_SendAsync_System_String_System_Threading_CancellationToken__examples">Examples</h4>
  <p>Getting a response from the model:</p>
<pre><code class="lang-csharp">var response = await chat.SendAsync("Write a haiku about AI models");
await foreach (var answerToken in response)
	 Console.WriteLine(answerToken);</code></pre>







</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/JerrettDavis/OllamaSharp/blob/feature/add-documentation/src/Chat.cs/#L41" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          <span>Made with <a href="https://dotnet.github.io/docfx">docfx</a></span>
        </div>
      </div>
    </footer>
  </body>
</html>
