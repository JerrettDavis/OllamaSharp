# Introduction

[Ollama](https://ollama.com/) is a [Go](https://go.dev/)-based, open-source 
server for interacting with local Large Language Models using Georgi Gerganov's
[llama.cpp](https://github.com/ggerganov/llama.cpp) library. Ollama provides 
first-class support for various models, including [llama3.2](https://ollama.com/library/llama3.2),
[phi3.5](https://ollama.com/library/phi3.5), [mistral](https://ollama.com/library/mistral),
and many more. It provides support for pulling, running, creating, pushing, and interacting
with models.

The [OllamaSharp](https://github.com/awaescher/OllamaSharp) library provides 
complete coverage of the Ollama API through simple, asynchronous streaming interfaces.
The library further ads convenience classes and functions to simplify common use cases.
